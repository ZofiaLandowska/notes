{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZofiaLandowska/notes/blob/main/Project2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Project #2\n",
        "##Name: Zofia Landowska \n",
        "\n",
        "Proposed Points (out of 25):"
      ],
      "metadata": {
        "id": "rIepkBIuT_Pl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Problem\n",
        "State the problem you are trying to solve with this machine learning experiment. Include a description of the data, where you got the data, and what you're trying to predict.."
      ],
      "metadata": {
        "id": "HbwKLNhzP8YO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*your answer here*"
      ],
      "metadata": {
        "id": "LwseoUsMmCz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Data Preparation\n",
        "Explain your data preparation. What did you have to do to get your data in shape for your experiments? Why are you certain that you data is clean and prepared for use in your algorithms?"
      ],
      "metadata": {
        "id": "qR_foVOeQVL7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*your answer here*"
      ],
      "metadata": {
        "id": "aMDJDnW_mOWu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "2wiB_mhn1G0O",
        "outputId": "b968f3cb-b063-4304-d1fa-1fc4e9bbe792",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load and prepare your data here\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "path = '/content/drive/MyDrive/NFLX.csv'\n",
        "data = pd.read_csv(path)\n",
        "df = pd.read_csv(path, parse_dates=['Date'])\n",
        "\n",
        "x = df.drop('Open', axis=1)\n",
        "y = df['Open']\n",
        "\n",
        "print(data.isnull().sum())\n",
        "\n",
        "#X = pd.get_dummies(X, columns=['categorical_variable'])\n",
        "\n",
        "scaler = StandardScaler()\n",
        "df[\"Open\", \"High\", \"Low\", \"Close\", \"Adj Close, Volume\"] = scaler.fit_transform(df[\"Open\", \"High\", \"Low\", \"Close\", \"Adj Close, Volume\"])"
      ],
      "metadata": {
        "id": "9dUdBChRmKxR",
        "outputId": "a223701b-c5d7-4a4b-90cf-8cbc9f90796d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Date         0\n",
            "Open         0\n",
            "High         0\n",
            "Low          0\n",
            "Close        0\n",
            "Adj Close    0\n",
            "Volume       0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Research\n",
        "\n",
        "Put your code and your experiments here."
      ],
      "metadata": {
        "id": "Hc7HMmNPR10W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code goes here... don't forget to include graphs. Professor Urness loves graphs.\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        " \n",
        "model = Sequential()\n",
        "model.add(Dense(64, activation='relu', input_dim=6))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mae', metrics=['mae'])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "XfaACsEOR4U5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist = model.fit(x, y, validation_split=0.2, epochs=50, batch_size=32)"
      ],
      "metadata": {
        "id": "Lch7XpjdXzDS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "\n",
        "err = hist.history['mae']\n",
        "val_err = hist.history['val_mae']\n",
        "epochs = range(1, len(err) + 1)\n",
        "\n",
        "plt.plot(epochs, err, '-', label='Training MAE')\n",
        "plt.plot(epochs, val_err, ':', label='Validation MAE')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Mean Absolute Error')\n",
        "plt.legend(loc='upper right')\n",
        "plt.plot()"
      ],
      "metadata": {
        "id": "76ys3JRDX1VX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "\n",
        "r2_score(y, model.predict(x)) "
      ],
      "metadata": {
        "id": "7GnFlmZSX4KW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# day of the week, time, and distance\n",
        "model.predict(np.array([[4, 17, 2.0]]))"
      ],
      "metadata": {
        "id": "NBWIv8H1X61d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. Analysis\n",
        "\n",
        "What did you discover? What insights/recommendations do you have? What did you find that was interesting? Which model was your best model, which models didn't work well? Why do you think this is? In general, I want a discussion of your experiment, the results, and what they mean."
      ],
      "metadata": {
        "id": "2Qu9bYPLmiv_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*your answer here*"
      ],
      "metadata": {
        "id": "k17sKBZUmqIH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Bumps in the Road\n",
        "What challenges did you encounter? How did you overcome these challenges?"
      ],
      "metadata": {
        "id": "TemAuKxlm6dQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*your answer here*"
      ],
      "metadata": {
        "id": "zXEVEG9FnHgQ"
      }
    }
  ]
}